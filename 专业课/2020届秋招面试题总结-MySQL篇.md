## 2020届秋招面试题总结——MySQL篇

**1、数据库隔离级别有哪些，各自的含义是什么，MySQL默认的隔离级别是多少。**

隔离级别有四种。

- 读未提交（Read Uncommitted）：只处理更新丢失。如果一个事务已经开始写数据，则不允许其他事务同时进行写操作，但允许其他事务读此行数据。可通过“排他写锁”实现。
- 读提交（Read Committed）：处理更新丢失、脏读。读取数据的事务允许其他事务继续访问改行数据，但是未提交的写事务将会禁止其他事务访问改行。可通过“瞬间共享读锁”和“排他写锁”实现。
- 可重复读取（Repeatable Read）：处理更新丢失、脏读和不可重复读取。读取数据的事务将会禁止写事务，但允许读事务，写事务则禁止任何其他事务。可通过“共享读锁”和“排他写锁”实现。
- 序列化（Serializable）：提供严格的事务隔离。要求失去序列化执行，事务只能一个接一个地执行，不能并发执行。仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。

MySQL默认的隔离级别是可重复读。

**事务的特性（ACID）

原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；

一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；如转账业务，无论事务执行成功与否，参与转账的两个账户余额之和应该保持不变。

隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；比如说购票系统，多个窗口同时购票，也就相当于并发访问数据库，隔离性不够的话很有可能同一张票被多个窗口购买。隔离性也指各个独立事务之间的交互程度，是由一致性和并发性共同决定的。并发性越低，事务的隔离性越高，一致性也就越高。当提高事务的隔离性的时候，就很可能需要牺牲数据库的并发性来保证数据的一致性。所以当设置事务的隔离级别的时候，就需要综合考虑事务的一致性和并发性。

持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。也就是你买了电影票，电影院收了你的钱，不能说系统崩溃了就说买的电影票失效。

**并发事务带来的问题

（1）更新丢失
两个事务都同时更新一行数据，一个事务对数据的更新把另一个事务对数据的更新覆盖了。这是因为系统没有执行任何的锁操作，因此并发并没有被隔离开来。

（2）脏读
一个事务读取到了另一事务未提交的数据操作结果。这是相当危险的，因为很可能所有的操作都被回滚。

（3）不可重复读
不可重复读（Non-repeatable Reads）：一个事务对同一行数据重复读取两次，但是却得到了不同的结果。

包括以下情况：

虚读：事务T1读取某一数据后，事务T2对其做了修改，当事务T1再次读取该数据时得到与前一次不同的值。
幻读：事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据或者缺少了第一次查询中出现的数据。这是因为在两次查询过程中有另外一个事务插入数据造成的。

**2、什么是幻读。**

幻读是指在同一个事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。

事务A读取与搜索条件相匹配的若干行，事务B以插入或删除行等方式来修改事务A的结果集，然后再提交，就会发生幻读。例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还存在没有修改的数据行，就好象发生了幻觉一样。

在默认的事务隔离级别下，即REPEATABLE READ（可重复读）下，InnoDB存储引擎采用**Next-Key Locking**机制来避免幻读。

具体看《MySQL技术内幕-InnoDB存储引擎》的6.4.2小节。

**3、MySQL有哪些存储引擎，各自优缺点。**

MySQL支持InnoDB、MyISAM、MEMORY等存储引擎。

InnoDB引擎（MySQL5.5以后默认使用）：

- 灾难恢复性好
- 支持事务
- 使用行级锁和表级锁，能支持更多的并发量
- 查询不加锁
- 支持外键关联
- 支持热备份
- 实现缓冲管理

MyISAM引擎：

- 不支持事务
- 使用表级锁，并发性差
- 主机宕机后，MyISAM表易损坏，灾难恢复性不佳
- 可以配合锁，实现操作系统下的复制备份、迁移
- 只缓存索引
- 数据紧凑存储，因此可获得更小的索引和更快的全表扫描性能

两者主要区别：

- InnoDB支持事务，MyISAM不支持事务处理等高级处理。
- InnoDB支持行级锁，而MyISAM仅支持表级锁。
- MyISAM类型的表强调的是性能，其执行速度比InnoDB类型更快。
- MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用。
- InnoDB支持外键，MyISAM不支持。
- MyISAM支持全文搜索，而InnoDB 1.2.x版本后才支持。
- 对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引。

**4、高并发下，如何做到安全的修改同一行数据。**

- 使用悲观锁。本质是当前只有一个线程执行操作，排斥外部请求的修改。遇到加锁的状态，就必须等待。结束了唤醒其他线程进行处理。但是，我们的场景是“高并发”。也就是说，会很多这样的修改请求，每个请求都需要等待“锁”，某些线程可能永远都没有机会抢到这个“锁”，这种请求就会死在那里。
- FIFO（先进先出）缓存队列思路，直接将请求放入队列中，这样就不会导致某些请求永远获取不到锁。有点强行把多线程变成单线程的感觉。
- 使用乐观锁。相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败。

**5、乐观锁和悲观锁是什么，InnoDB的标准行级锁有哪两种，解释其含义。**

悲观锁和乐观锁是两种常见的资源并发锁设计思路。

**悲观锁**：它指的是对数据被外界（包括当前系统的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁是使用数据库内部的锁（排他锁）对记录进行加锁，从而使得其他事务等待以保证数据的一致性。**通常通过常用的select … for update操作来实现悲观锁**，在SQL的最后加入for update语句，就可以在数据库事务执行过程中，锁定查询出来的数据，其他事务将不能再对其进行读写操作，这样避免了数据的不一致，单个请求直至数据库事务完成，才会释放这个锁。

**乐观锁**：是指一种不使用数据库锁和不阻塞线程并发的思路。它的特点是先进行业务操作，不到万不得已不去拿“锁”。即“乐观”的认为拿锁多半是会成功的，因此在进行完业务操作需要实际更新数据的最后一步再去拿一下锁就好。乐观锁在数据库的实现完全是逻辑的，不需要数据库提供特殊的支持，一般的做法是在需要锁的数据上增加一个版本号，或者时间戳。

InnoDB存储引擎实现了两种标准的行级锁：

- 共享锁（S Lock），允许事务读一行数据，可以多个事务同时获取，也成为锁兼容。但阻止其他事务获得相同数据集的排他锁。
- 排他锁（X Lock），允许事务删除或更新一行数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁，这两种意向锁都是表级别的锁。

表锁

- 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁，事务再给一个数据行加共享锁之前必须先取得该表的IS锁。
- 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁，事务在给一个数据行加排他锁之前必须先取得该表的IX锁。

简洁来说，悲观锁就是用共享锁和排他锁；而乐观锁，实际通过版本号，从而实现CAS原子性更新。

**5、SQL优化的一般步骤是什么，怎么看执行计划，如何理解其中各个字段的含义。**

SQL优化步骤一般是：

- 通过show status命令了解各种SQL的执行频率
- 定位执行效率较低的SQL语句
- 通过EXPLAIN分析较低SQL的执行计划
- 通过show profile分析SQL
- 通过trace分析优化器如何选择执行计划
- 确定问题并采取相应的优化措施

执行计划是SQL在数据库执行时的表现情况，通常用于SQL性能分析、优化等场景。在MySQL中使用explain关键字来查看。

参考链接： [SQL优化的一般步骤是什么，怎么看执行计划，如何理解其中各个字段的含义。](https://blog.csdn.net/riemann_/article/details/91349161)

**6、数据库会死锁吗，举一个死锁的例子，mysql是怎么解决死锁的。**

数据库会出现死锁。死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种相互等待的现象。

举个例子，一个用户A 访问表A（锁住了表A），然后又访问表B；另一个用户B 访问表B（锁住了表B），然后企图访问表A；这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了。

解决死锁最简单的方式是不要有等待，将任何的等待都转换为回滚，并且事务重新开启。但这可能导致并发性能的下降，甚至任何一个事务都不能进行。这个方法不适用。

另一个简单方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。

除了超时机制外，当前数据库还都普遍采用wait-for graph（等待图）的方式来进行死锁检测，这是一种更为主动的死锁检测方式，InnoDB存储引擎中也采用这种方式。

**7、MySQL的索引原理，索引的类型有哪些，如何创建合理的索引，索引如何优化。** 

MySQL中索引采用的数据结构主要是B+Tree，Hash，平衡二叉树等。

索引的类型可以分为：

- 普通索引（INDEX），最基本的索引，没有任何的约束。INDEX index_name (name)
- 唯一索引（UNIQUE），与普通索引类似，但索引列的值必须唯一，但允许有控制（注意和主键不同）。如果是组合索引，则列值的组合必须唯一，创建方法和普通索引类似。UNIQUE index_name (name)
- 全文索引（ FULLTEXT ），MyISAM 表全系支持，InnoDB 1.2.x后支持。FULLTEXT (content)
- 主键索引（PRIMARY KEY），特殊的唯一索引，一个表只能有一个，不允许有空值。
- 复合索引，将多个列组合在一起创建索引，可以覆盖多个列。

索引如何优化：

- 非空字段 NOT NULL，Mysql 很难对空值作查询优化
- 区分度高，离散度大，作为索引的字段值尽量不要有大量相同值
- 索引的长度不要太长（比较耗费时间）

索引的最左匹配特性：
	简单来说就是你的数据来了以后，从数据块的左边开始匹配，再匹配右边的，知道这句话就行啦，我们继续学下面的内容。当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的。
比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。
	最左匹配遇到范围查询后就停止

**B树
	1）子节点数：非叶节点的子节点数>1，且<=M ，且M>=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）；
	2）关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2);
	3）所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子;

**B+树
B+树是对B树的一种变形树，它与B树的差异在于：
	1）有k个子结点的结点必然有k个关键码，B树是有k-1个关键码
	2）非叶结点仅具有索引作用，所有数据均存放在叶结点中
	3）树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。

B+树的优点：
	1）IO次数更少：由于B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子节点上关联的数据也具有更好的缓存命中率。
	2）遍历更加方便：B+树的叶子结点都是相链的，因此对整棵树的遍历只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。
相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。

为什么MySQL选择B+树做索引
	1）B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，
那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。
	2）B+树的查询效率更加稳定：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。
	3）B+树更便于遍历：由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，
需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。
	4）B+树更适合基于范围的查询：B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。
而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。

**8、聚集索引和辅助索引的区别。**

非聚集索引也称之为辅助索引。聚集索引与辅助索引不同的是，叶子节点存放的是否是一整行的数据。聚集索引叶子节点存放的即为整张表的行记录数据；而辅助索引叶子节点除了包含键值以外，还包含了一个书签（bookmark），该书签用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。由于InnoDB存储引擎表是索引组织表，因此**InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键。**所以，聚集索引一般比辅助索引体积大。

由于实际的数据页只能按照一颗B+树进行排序，因此**每张表只能拥有一个聚集索引**。在多数情况下，查询优化器倾向于采用聚集索引。因为聚集索引能够在B+树索引的叶子节点上只能找到数据。

聚集索引的好处在于
	1）它对主键的排序查找和范围查找速度非常快，叶子节点的数据就是用户所要查询的数据。如用户需要查找一张表，查询最后的10位用户信息，由于B+树索引是双向链表，所以用户可以快速找到最后一个数据页，并取出10条记录
	2）范围查询（range query），即如果要查找主键某一范围内的数据，通过叶子节点的上层中间节点就可以得到页的范围，之后直接读取数据页即可
聚集索引的缺点
	1）新增数据比较慢，因为数据有序，所以需要对数据页重新进行排序

需要注意的是：

- 如果一个主键被定义了，那么这个主键就是作为聚集索引。
- 如果没有主键被定义，那么该表的第一个唯一非空索引被作为聚集索引。
- 如果没有主键也没有合适的唯一索引，那么innodb内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，改列的值会随着数据的插入自增。
- 一个表只能有一个聚集索引

辅助索引：

	就是我们在查询的时候，where后面需要写id之外的其他字段名称来进行查询，比如说是where name=xx，没法用到主键索引的效率，怎么办，就需要我们添加辅助索引了，给name添加一个辅助索引。

　　表中除了聚集索引外其他索引都是辅助索引（Secondary Index，也称为非聚集索引）（unique key啊、index key啊），与聚集索引的区别是：辅助索引的叶子节点不包含行记录的全部数据。

　　叶子节点存放的是对应的那条数据的主键字段的值，除了包含键值以外，每个叶子节点中的索引行中还包含一个书签（bookmark），其实这个书签你可以理解为是一个{'name字段'，name的值，主键id值}的这么一个数据。
该书签用来告诉InnoDB存储引擎去哪里可以找到与索引相对应的行数据。如果我们select 后面要的是name，我们直接就可以在辅助索引的叶子节点找到对应的name值，比如：select name from tb1 where name='xx'；
这个xx值你直接就在辅助索引的叶子节点就能找到，这种我们也可以称为覆盖索引。如果你select后面的字段不是name，例如：select age from tb1 where name='xx'；也就是说，我通过辅助索引的叶子节点不能直接拿到age的值，
需要通过辅助索引的叶子节点中保存的主键id的值再去通过聚集索引来找到完整的一条记录，然后从这个记录里面拿出age的值，这种操作有时候也成为回表操作，就是从头再回去查一遍，这种的查询效率也很高，但是比覆盖索引低一些，
再说一下昂，在辅助索引的叶子节点就能找到你想找的数据可称为覆盖索引。


**9、select for update是什么含义，会锁表还是锁行还是其他。**

select for update会锁定查询出来的数据，其他事务将不能再对其进行读写操作，这样避免了数据的不一致，单个请求直至数据库事务完成，才会释放这个锁。**记住，for update是排他锁。**

当使用select ... for update ...where ...时，mysql进行row lock还是table lock只取决于是否有明确的指定主键，能则为行锁，否则为表锁；未查到数据则无锁。


**12、某一个表有近千万的数据，CRUD（增删改查）比较慢，如何优化。**

- 可以做表拆分，减少单表字段数量，优化表结构。
- 在保证主键有效的情况下，检查主键索引的字段顺序，使得查询语句中条件的字段顺序和主键索引的字段顺序保持一致。
- 建立合理的索引。
- 可以结合Redis、Memcache等缓存服务，把复杂的SQL进行拆分，充分利用二级缓存，减少数据库IO操作。

参考链接： [某个表有近千万数据，CRUD比较慢，如何优化？](https://blog.csdn.net/riemann_/article/details/93676341)

**13、MySQL是怎么优化table scan的。**

对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。

避免全表扫描的优化方案：

- 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num is null
- 应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。
- 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num=10 or num=20。也可以这样查询： select id from t where num=10 union all select id from t where num=20
- in 和 not in 也要慎用，否则会导致全表扫描，如：select id from t where num in(1,2,3) 。可以用between来代替in，如select id from t where num between 1 and 3
- 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where num/2=100。应改为：select id from t where num=100*2

**14、如何写SQL能够有效地使用到复合索引。**

复合索引也叫组合索引，用户可以在多个列上建立索引,这种索引叫做复合索引(组合索引)。复合索引在数据库操作期间所需的开销更小,可以代替多个单一索引。

创建复合索引：CREATE INDEX columnId ON table1(col1,col2,col3) ;

使用复合索引：select * from table1 where col1= A and col2= B and col3 = C

对于复合索引,在查询使用时,最好将条件顺序按找索引的顺序,这样效率最高。

复合索引可以用到多个where条件查询下，比如查询年龄是12和性别是男的所有学生。这样避免了多一次的排序操作。

参考链接： [如何写sql能够有效的使用到复合索引](https://blog.csdn.net/riemann_/article/details/94840416)

另外，**联合索引具有最左匹配原则，即最左优先。**比如，我们建立了一个2列的联合索引(col1,col2),实际上已经建立了两个联合索引(col1)、(col1,col2），解释如下。

B+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道第一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了（这种情况下无法使用联合索引）。 

联合索引的意义在于：

- 一个顶三个。建了一个(a,b,c)的复合索引，那么实际等于建了(a),(a,b),(a,b,c)三个索引，因为每多一个索引，都会增加写操作的开销和磁盘空间的开销。
- 作为覆盖索引。同样的有复合索引（a,b,c），如果有如下的sql: select a,b,c from table where a=1 and b = 1。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。
- 索引列越多，通过索引筛选出的数据越少。

参考链接：[Mysql中联合索引的最左匹配原则](https://www.cnblogs.com/wangkaihua/p/10220462.html)

**15、MySQL中in和exists的区别。**

in和exists主要用在子查询：

```sql
select * from A where id in (select id from B);
select * from A where exists (select 1 from B where A.id=B.id);
```

两者区别在于：

- exists是对外表做loop循环，每次loop循环再对内表（子查询）进行查询，那么因为对内表的查询使用的索引（内表效率高，故可用大表），而外表有多大都需要遍历，不可避免（尽量用小表），故内表大的使用exists，可加快效率。
- in是把外表和内表做hash连接，先查询内表，再把内表结果与外表匹配，对外表使用索引（外表效率高，可用大表），而内表多大都需要查询，不可避免，故外表大的使用in，可加快效率。

外层查询表小于子查询表，则用exists，外层查询表大于子查询表，则用in。

**16、数据库自增主键可能的问题。**

自增长是一个很常见的数据属性，在MySQL中我很喜欢让一个自增长属性的字段（比如ID）当作一个主键。特别是InnoDB，因为InnoDB的聚集索引特性，使用自增长属性的字段当主键性能更好。但是也存在一些问题。

首先是MyISAM引擎下，由于该引擎是表锁设计，所以自增长不用考虑并发插入的问题。

然后来到较为复杂的InnoDB引擎情况下。在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器。当对含有自增长的计数器的表进行插入操作时，这个计数器会被初始化，执行语句来得到计数器的值。

```sql
SELECT MAX(auto_inc_col) FROM t FOR UPDATE
```

插入操作会依据这个自增长的计数器值加1赋予自增长列。这个实现方式称作AUTO-INC Locking，这种锁其实是一种特殊的表锁机制，为了提高插入的性能，锁不是在一个事务完成后才释放，而是在完成自增长值插入的SQL语句后立即释放。

虽然AUTO-INC Locking从一定程度上提高了并发插入的效率。但还是存在一些性能上的问题。首先，插入性能较差，事务必须等待前一个插入的完成。其次，对于INSERT...SELECT的大数据量的插入会影响插入的性能，因为另一个事务的插入会被阻塞。

从MySQL 5.1.22版本开始，InnoDB引擎提供了一种轻量级互斥量的自增长实现机制，提高了自增长插入的性能。

另外，在InnoDB引擎中，自增长值的列必须是索引，同时必须是索引的第一列，如果不是会抛出异常，而MyISAM引擎没有这个问题。

参考《MySQL技术内幕-InnoDB存储引擎》的6.3.4小节-自增长与锁

另外，在多机数据库设计中，自增长主键ID会有重复现象，这也导致了系统设计时单点数据库不能拆库，因为ID会重复。

**17、MVCC的含义，如何实现的。**

MVCC(Multi Version Concurrency Control的简称)，代表多版本并发控制。与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control)。

MVCC，是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读。

undo log可以实现MVCC

MVCC最大的优势：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能。

MVCC是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的过期时间（或删除时间）。当然存储的并不是实际的时间值，而是系统版本号（system version number)。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

参考链接：[MVCC的含义，如何实现的？](https://blog.csdn.net/riemann_/article/details/94838870)


**21、B+Tree索引和Hash索引区别？**

在InnoDB存储引擎使用哈希算法对字典进行查找，其冲突机制采用链表方式（与JDK1.7的HashMap一样）。

- 哈希索引是自适应索引，InnoDB存储引擎会根据表的使用情况自动为表生成哈希索引，是无法人为干预的。
- 哈希索引适合等值查询，但是无法进行范围查询。
- 哈希索引没办法利用索引完成排序。
- 哈希索引不支持多列联合索引的最左匹配规则。
- 如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题

**22、在Mybatis中，占位符$和#的区别（防止SQL注入）。**

先举例来说明，看一个很简单的MySQL的Mapper。

```sql
<select id="getById" resultType="Blog" parameterType=”int”>
         SELECT id,title,author,content
         FROM blog
WHERE id=#{id}
</select>
```

这里，parameterType表示了输入的参数类型，resultType表示了输出的参数类型。回应上文，如果我们想防止SQL注入，理所当然地要在输入参数上下功夫。上面代码中WHERE id=#{id}即输入参数在SQL中拼接的部分，传入参数后，打印出执行的SQL语句，会看到SQL是这样的：

```sql
SELECT id,title,author,content FROM blog WHERE id = ?
```

不管输入什么参数，打印出的SQL都是这样的。这是因为MyBatis启用了预编译功能，在SQL执行前，会先将上面的SQL发送给数据库进行编译；执行时，直接使用编译好的SQL，替换占位符“?”就可以了。因为SQL注入只能对编译过程起作用，所以这样的方式就很好地避免了SQL注入的问题。

【底层实现原理】MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。

话说回来，是否我们使用MyBatis就一定可以防止SQL注入呢？当然不是，请看下面的代码：

```sql
<select id="getById" resultType="Blog" parameterType=”int”>
         SELECT id,title,author,content
         FROM blog
WHERE id=${id}
</select>
```

仔细观察，内联参数的格式由“#{xxx}”变为了“${xxx}”。如果我们给参数“id”赋值为“3”，将SQL打印出来是这样的：

```sql
SELECT id,title,author,content FROM blog WHERE id = 3
```

显然，这样是无法阻止SQL注入的。在MyBatis中，“${xxx}”这样格式的参数会直接参与SQL编译，从而不能避免注入攻击。但涉及到动态表名和列名时，只能使用“${xxx}”这样的参数格式。所以，这样的参数需要我们在代码中手工进行处理来防止注入。比如

```sql
<select id="order" resultType="Blog" parameterType=”map”>
         SELECT id,title,author,content
         FROM blog
ORDER BY ${orderParam}
</select>
```

如果我们给参数“orderParam”赋值为“id”，将SQL打印出来是这样的：

```
SELECT id,title,author,content FROM blog ORDER BY id
```

在编写MyBatis的映射语句时，尽量采用“#{xxx}”这样的格式。若不得不使用“${xxx}”这样的参数，要手工地做好过滤工作，来防止SQL注入攻击。

- #{}：相当于JDBC中的PreparedStatement。

- ${}：是输出变量的值。

简单说，#{}是经过预编译的，是安全的；${}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。

如果我们order by语句后用了${}，那么不做任何处理的时候是存在SQL注入危险的，必须要事先手动处理过滤一下输入的内容。

参考文章：[Mybatis如何防止SQL注入](https://www.cnblogs.com/200911/p/5869097.html)

**23、SQL的注入攻击是什么，如何防范。**

SQL注入攻击，就是通过把SQL命令插入到Web表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。

解决SQL注入问题的关键是对所有可能来自用户输入的数据进行严格的检查，对数据库配置使用最小权限原则。有几种防范方法：

- 在JDBC中，使用PreparedStatement来拼接动态字符串，可以保证输入的数据被视作SQL中纯粹的字符串，而不会当作SQL语法来解释。比如。

```java
String url="jdbcUrl";
String userName="userName";
String passWord="passWord";
Connection conn= DriverManager.getConnection(url);
PreparedStatement stmt=conn.prepareStatement("SELECT * FROM user_table WHERE username=? AND password=?");
stmt.setString(1,userName);
stmt.setString(2,passWord);
```

- 对进入数据库的特殊字符（’”\尖括号&*;等）进行转义处理，或编码转换。或者直接禁止用户向参数中写入特殊字符。
- 网站每个数据库的编码统一，建议全部使用utf-8编码，上下层编码不一致有可能导致一些过滤模型被绕过。
- 严格限制网站用户对数据库的操作权限，给此用户提供仅仅能够满足其工作的权限，从而最大限度地减少注入攻击对数据库的损坏。

**24、什么时候添加B+树索引。**

如果每个字段的取值范围很广，几乎没有重复，即属于高选择性，则此时使用B+树索引最合适。

怎么查看索引是否是高选择性的呢？可以通过SHOW INDEX结果中的列Cardinality（索引基数）来观察。Cardinality值非常关键，表示索引中不重复记录数量的预估值。同时需要注意的是，Cardinality是一个预估值，而不是一个准确值，基本上用户也不可能得到一个准确的值。在实际应用中，Cardinality/n_rows_in_table应尽可能地接近1。如果非常小，那么用户需要考虑是否还有必要创建这个索引。故在访问高选择性属性地字段并从表中去除很少一部分数据时，对这个字段添加B+树索引是非常有必要的。

另外，在InnoDB存储引擎中，Cardinality统计信息的更新发生在两个操作中：INSERT和UPDATE。当然，并不是每次发生INSERT和UPDATE时就去更新Cardinality信息。

**25、MySQL的嵌套事务。**

（这道题主要为了纪念当时华为的面试题。。。）

在InnoDB引擎下，MySQL是支持嵌套事务的。嵌套事务是一个层次结构框架，由一个顶层事务控制各个层次的事务。顶级事务之下嵌套的事务被称为子事务，其控制着每一个局部的变换。需要注意的是：

- 子事务既可以提交也可以回滚，但它的提交操作并不马上生效，除非其父事务已经提交。因此可以推断出，任务子事务都在顶层事务提交后才真正的提交。
- 任何一个父事务的回滚会引起它所有的子事务一同回滚，故子事务仅保留A、C、I特征，不具有D特征（一致性）。

具体看《MySQL技术内幕-InnoDB存储引擎》7.1.2小节中的嵌套事务部分。

**26、给出一个学生成绩studuent表，写一个SQL语句，统计每个学生所有成绩平均分大于80分的结果。**

这个问题主要考察GROUP BY和HAVING语句的联合使用，答案如下。

```sql
SELECT id, COUNT(course) as numcourse, AVG(score) as avgscore
FROM student
GROUP BY id
HAVING AVG(score)>=80;
```

在select语句中可以使用groupby子句将行划分成较小的组，然后，使用聚组函数返回每一个组的汇总信息，另外，可以使用having子句限制返回的结果集。HAVING语句的存在弥补了WHERE关键字不能与聚合函数联合使用的不足。

HAVING 子句对 GROUP BY 子句设置条件的方式与 WHERE 和 SELECT 的交互方式类似。WHERE 搜索条件在进行分组操作之前应用；而 HAVING 搜索条件在进行分组操作之后应用。

HAVING 语法与 WHERE 语法类似，但 HAVING 可以包含聚合函数。HAVING 子句可以引用选择列表中显示的任意项。

**27、MySQL中一条SQL语句的执行过程。**

SQL是一套标准，是用来完成和数据库之间的通信的编程语言，SQL语言是脚本语言，直接运行在数据库上。同时，SQL语句与数据在数据库上的存储方式无关，只是不同的数据库对于同一条SQL语句的底层实现不同罢了，但结果相同。SQL语句如下，序号则为实际执行顺序：

```sql
(7) SELECT
(8) DISTINCT <select_list>
(1) FROM <left_table>
(3) <join_type> JOIN <right_table>
(2) ON <join_condition>
(4) WHERE <where_condition>
(5) GROUP BY <group_by_list>
(6) HAVING <having_condition>
(9) ORDER BY <order_by_condition>
(10) LIMIT <limit_number>
```


建议直接去看这篇文章：[SQL查询之执行顺序解析](http://zouzls.github.io/2017/03/23/SQL%E6%9F%A5%E8%AF%A2%E4%B9%8B%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%E8%A7%A3%E6%9E%90/)

**28、MySQL中int(11)中的11代表什么含义。**

nt(11) 中的 11 ，不影响字段存储的范围，只影响展示效果。当数字不足11位时，前面会用0补齐。

mysql中int长度并不影响数据的存储精度，长度只与显示有关。无论是int(3)还是int(9)，存储的都是4字节无符号整数，也就是0~2^32。

**29、InnoDB 中为什么采用B+树结构，而不是平衡树。**

数据库文件很大，不可能全部存储在内存中，故要存储到磁盘上。索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。索引采用B/+Tree而不是二叉查找树，关键因素就是磁盘I/O次数。这是一种**多路搜索树**，而不是简单的二叉树。

**BTree** 是为磁盘等外存储设备设计的一种平衡查找树。因此在讲 B-Tree 之前先了解下磁盘的相关知识。

- 系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。
- InnoDB 存储引擎中默认每个页的大小为 16 KB，可通过参数 innodb_page_size 将页的大小设置为 4K、8K、16K ，在 MySQL 中可通过如下命令查看页的大小：

```SQL
mysql> show variables like 'innodb_page_size';
```

- 而系统一个磁盘块的存储空间往往没有这么大，因此 InnoDB 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小 16KB 。InnoDB 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘 I/O 次数，提高查询效率。

BTree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述BTree，首先定义一条记录为一个二元组 [key, data] ，key 为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。BTree结构如下图所示。

![Y4yrpF.png](https://s1.ax1x.com/2020/05/19/Y4yrpF.png)

**B+Tree** 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用 B+Tree 实现其索引结构。从刚刚的B-Tree 结构图中可以看到，每个节点中不仅包含数据的 key 值，还有 data 值。而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小，当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。在 B+Tree 中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储 key 值信息，这样可以大大加大每个节点存储的 key 值数量，降低 B+Tree 的高度。

B+Tree 相对于 BTree 有几点不同：

- 非叶子节点只存储键值信息。
- 所有叶子节点之间都有一个链指针。
- 数据记录都存放在叶子节点中。

将 B-Tree 优化，由于 B+Tree 的非叶子节点只存储键值信息，假设每个磁盘块能存储 4 个键值及指针信息，则变成 B+Tree 后其结构如下图所示：

![Y4yhtK.png](https://s1.ax1x.com/2020/05/19/Y4yhtK.png)

**总结一波：**因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低。

参考文章：[为什么数据库选B-tree或B+tree而不是二叉树作为索引结构](https://blog.csdn.net/sinat_27602945/article/details/80118362)

**30、MySQL索引的“创建”原则。**

可以结合24题一起来看。主要在以下几种条件下，推荐创建索引。

- 最适合索引的列是出现在 WHERE 子句中的列，或连接子句中的列，而不是出现在 SELECT 关键字后的列。
- 索引列的基数Cardinality越大，索引效果越好。
- 根据情况创建复合索引，复合索引可以提高查询效率。因为复合索引的基数会更大。
- 避免创建过多的索引，索引会额外占用磁盘空间，降低写操作效率。
- 主键尽可能选择较短的数据类型，可以有效减少索引的磁盘占用提高查询效率。
- 对字符串进行索引，应该定制一个前缀长度，可以节省大量的索引空间。

**31、为什么官方建议使用自增长主键作为索引。**

结合B+Tree的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率。

**32、MySQL主从复制的作用和原理。**

主从复制，是用来建立一个和主数据库完全一样的数据库环境，称为从数据库。主数据库一般是准实时的业务数据库。

主从复制的好处是从数据库可以作为数据的热备份，作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失。还可以支持读写分离，在主数据库上进行写入工作，在从数据库执行查询工作，支持更大的并发性能。

先介绍两个**重要概念**。

- 主库bin-log：二进制日志，记录主库发生的修改事件。
- 从库relay-log：中继日志，存储所有主库TP过来的bin-log事件。

主从复制库的原理：

- 数据库有一个bin-log的二进制文件，记录了所有的SQL语句。
- 目标就是把主数据库的bin-log文件的SQL语句复制过来。
- 让其在从数据库的relay-log重做日志文件中再执行一次这些SQL语句即可。

具体操作过程需要三个线程。

- bin-log输出线程：每当从库连接到主库的时候，主库都会创建一个线程，然后发送bin-log内容到从库。在从库里，当复制开始的时候，从库就会创建两个线程进行处理。
- 从库I/O线程：当START SLAVE语句在从库开始执行之后，从库创建一个I/O线程，该线程连接到主库并请求主库发送到bin-log里面的更新记录到从库中，从库I/O线程读取主库的bin-log输出线程发送的更新并拷贝这些更新到本地文件，其中包括relay-log文件（中继日志）。
- 从库的SQL线程：从库创建一个SQL线程，这个线程读取从库I/O线程写到relay log的更新事件并执行。

从上可知，对于每一个主从复制的连接，都有三个线程。拥有多个从库的主库为每一个连接到主库的从库创建一个bin-log输出线程，每一个从库都有它自己的I/O线程和SQL线程。

![Y4yz9S.png](https://s1.ax1x.com/2020/05/19/Y4yz9S.png)

**33、MySQL事务日志。**

innodb事务日志包括redo log和undo log。redo log是重做日志，提供前滚操作；undo log是回滚日志，提供回滚操作。

- redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。又叫做重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。如数据库掉电后，InnoDB存储引擎会使用redo log来恢复到掉电前的时刻，以此来保证数据的完整性。
- undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。

**redo log**

事务中所有操作会先写到redo log中，然后再同步到数据库文件中。所以数据库文件进行事务操作修改时，redo log肯定已经记录了所有事务操作，此时即使数据库挂掉，事务操作也都已经持久化到redo log中了，数据库恢复后可以继续执行剩下操作。它保证了事务的**一致性**。

**undo log**

undo log有两个作用：

- 提供回滚
- 多个行版本控制(MVCC)

undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。

undo log是采用**段(segment)的方式**来记录的，每个undo操作在记录的时候占用一个undo log segment。

它保证了事务的**原子性**。

**34、JOIN的用途。**

JOIN 按照功能大致分为如下三类：

- INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录。
- LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。
- RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。

**35、PreparedStatement和Statement的区别。**

- PreparedStatement接口继承于Statement，PreparedStatement是**预编译**的，实例中包含的是已编译好的SQL语句，执行速度要快于Statement对象。以后每当执行同一个PreparedStatement对象时，预编译的命令是可以重复使用的。
- PreparedStatement可以**防止SQL注入式攻击**，在使用参数化查询的情况下，数据库系统不会将参数的内容视为SQL指令的一部分来处理，而是在数据库完成SQL指令的编译后，才套用参数运行，因此就算参数中含有破坏性的指令，也不会被数据库所运行。

**36、数据库第一、第二、第三范式的理解。**

**第一范式，是指没有重复的列，**表示数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。在第一范式（1NF）中表的每一行只包含一个实例的信息。简而言之，第一范式就是无重复的列。

**第二范式，是指属性完全依赖主键，**要求数据库表中的每个实例或行必须可以被惟一地区分。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。例如员工信息表中加上了员工编号（emp_id）列，因为每个员工的员工编号是惟一的，因此每个员工可以被惟一区分。这个惟一属性列被称为主关键字或主键、主码。

**第三范式，是要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。**例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在的员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。简而言之，第三范式就是属性不依赖于其它非主属性。 也就是说， 如果存在非主属性对于码的传递函数依赖，则不符合3NF的要求。

**37、MySQL半同步复制原理。**

MySQL主从复制分为**异步、同步和半同步复制**，区别主要如下：

- 异步复制（Asynchronous replication），MySQL默认的复制是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理。原理最简单，性能最好，但是主从之间数据不一致的概率很大。
- 全同步复制（Fully synchronous replication），指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。
- 半同步复制（Semisynchronous replication），介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制牺牲了一定的性能，提高了数据的安全性。

**半同步复制原理：**

默认情况下，MySQL的主从复制是异步的，异步复制可以提供最佳的性能， 主库把binlog日志发送给从库，然后将结果返回给客户端，并不会验证从库是否接收完毕。这也就意味着有可能出现当主库或从库发生故障的时候，从库没有接收到主库发送过来的binlog日志，导致主库和从库的数据不一致，甚至在恢复时造成数据的丢失。为了解决上述出现的问题，MySQL 5.5 引入了一种半同步复制模式。该模式可以确保从库接收完主库发送的binlog日志文件并写入到自己的中继日志relay log里，然后会给主库一个反馈，告诉主库已经接收完毕，这时主库才返回结果给客户端告知操作完成。当出现从库响应超时情况时，主库会暂时切换到异步复制模式，直到下一次同步没有超时转为半同步复制为止。（master的dump线程除了发送binlog数据到slave，还承担了接收slave的ack工作。如果出现异常，没有收到ack，那么将自动降为普通的异步复制，直到异常修复）

**38、MySQL中Distinct与Group by的区别。**

distinct简单来说就是用来去重的，而group by的设计目的则是用来聚合统计的，两者在能够实现的功能上有些相同之处。

单纯的去重操作使用distinct，速度是快于group by的。



弥有，2019年9月